{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a7a58-1779-463f-89dd-82f5e821cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/generation_utils.py\n",
    "the repo have model.generate() func\n",
    "and the func can tell us how to use model and beam-search\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4903f17-bbd1-49d9-a954-75e28448b72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d01b4-96b2-4179-88be-09102ac5f851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830f934e-36e7-4512-8f5c-f9f466d644fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322d2d25-9361-496f-9398-db17076115e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Helsinki-NLP/opus-mt-en-zh'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2b7471-64aa-4f01-92ac-2ec29353da1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['这房子是美妙的。', '我喜欢在e. 6v工作']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"The house is wonderful.\", \"I like to work in u.6v\"]\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output_sequences = model.generate(input_ids=inputs[\"input_ids\"],\n",
    "                                  attention_mask=inputs[\"attention_mask\"],\n",
    "                                  do_sample=False)\n",
    "                                  # disable sampling to test if batching affects output\n",
    "tokenizer.batch_decode(output_sequences, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59cc278f-a9de-4d09-8589-e77c7424d7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65000,   789, 10095,    72, 37908,    12,    10,     0, 65000, 65000],\n",
       "        [65000, 13565,    38,   179,     6,     8,   135,  4068,   198,     0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e967ca36-b8d7-4019-a286-5fd546ea9a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   26,  2793,    32, 15099,     6,     0, 65000, 65000, 65000, 65000],\n",
       "        [   28,   240,     9,   119,    11,     8,  1508,  2157,  4068,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edc330bc-3f42-478c-b538-7f333c684a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.model.encoder(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "287f8dd9-b671-43a7-bbf0-8f93669763f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-9.2812e-02,  3.6446e-01,  9.4637e-02,  ..., -7.0080e-01,\n",
       "           6.8105e-04, -6.1914e-03],\n",
       "         [-2.1327e-01,  1.3161e-01,  1.9674e-01,  ..., -7.9506e-01,\n",
       "          -5.4278e-01, -1.4929e-01],\n",
       "         [ 3.3304e-02, -1.3072e-01,  4.9979e-01,  ..., -2.1106e-01,\n",
       "          -3.3489e-01, -1.5482e-01],\n",
       "         ...,\n",
       "         [ 1.8291e-01,  2.7879e-02,  2.5640e-02,  ..., -5.3971e-02,\n",
       "          -6.1518e-02,  1.7738e-02],\n",
       "         [ 2.2472e-01,  1.8369e-02,  5.8589e-02,  ..., -8.1724e-02,\n",
       "          -8.7148e-03,  6.4150e-02],\n",
       "         [ 1.6981e-01,  5.1836e-02,  1.9128e-01,  ..., -1.6713e-01,\n",
       "           1.7896e-01,  1.8652e-01]],\n",
       "\n",
       "        [[-1.0097e+00, -6.3492e-01,  2.1529e-01,  ..., -4.3858e-01,\n",
       "          -2.5724e-01, -1.2957e-01],\n",
       "         [-9.8106e-01, -2.2376e-01,  6.3795e-02,  ...,  2.9150e-01,\n",
       "          -3.7196e-02, -5.3129e-01],\n",
       "         [-5.5728e-02, -4.7423e-01,  8.9754e-02,  ...,  3.9865e-01,\n",
       "           5.9542e-02, -1.9249e-01],\n",
       "         ...,\n",
       "         [-1.4108e-01,  4.4221e-01,  2.9675e-01,  ..., -1.4283e-02,\n",
       "           2.9296e-01,  4.9406e-01],\n",
       "         [-3.1153e-01, -2.2317e-01, -1.7332e-01,  ..., -1.2193e-02,\n",
       "           2.2037e-01, -1.3753e-02],\n",
       "         [ 5.4853e-02, -7.7996e-02,  3.8141e-02,  ..., -3.9749e-01,\n",
       "          -4.3337e-01, -4.8541e-02]]], grad_fn=<NativeLayerNormBackward>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ca9e4b7-aa7f-4f1b-a8ab-9377c6f0ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19ba6303-0718-48f2-a34d-99880e0a0782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['past_key_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8db5fda-1c73-4e20-8360-fc0c2213dd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 10, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['past_key_values'][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc42cd4c-bcb9-4877-b742-765df417442b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13959,  1566,    12,  2968,    10,    37,   629,    19,  1627,     5,\n",
       "             1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34e06cf3-c478-45c9-ad31-fcb81e0761f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "input_ids = tokenizer('translate English to German: The house is wonderful.', return_tensors='pt').input_ids\n",
    "labels = tokenizer('Das Haus ist wunderbar.', return_tensors='pt').input_ids\n",
    "# the forward function automatically creates the correct decoder_input_ids\n",
    "loss = model(input_ids=input_ids, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61a469cc-3810-4a60-8dd5-4ab1cf71a29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2542, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e1129a9-f522-439f-924c-1d7421f27df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Helsinki-NLP/opus-mt-en-zh'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "db6085d7-3346-44f2-be90-5763297d9443",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://juejin.cn/post/7069225910427189256\n",
    "'''\n",
    "sentences = [\"The house is wonderful.\", \"I like to work in u.6v\"]\n",
    "label_seq = ['这房子是美妙的。', '我喜欢在e. 6v工作']\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)['input_ids']\n",
    "label_inputs = tokenizer(label_seq, return_tensors=\"pt\", padding=True)['input_ids']\n",
    "#\n",
    "loss = model(input_ids=inputs, labels=label_inputs).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3832f29d-137c-45e1-8523-25e58d28a697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7461, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "da34cf26-8dba-426f-9fce-012cdfe9c6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=inputs, labels=label_inputs, output_attentions=True, output_hidden_states=True, return_dict=True).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed31dcf3-b363-4a53-8837-78b6d4312641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 512])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=inputs, labels=label_inputs)['encoder_last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4750ee02-ae72-4934-96e1-a9b26aae075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   26,  2793,    32, 15099,     6,     0, 65000, 65000, 65000, 65000],\n",
       "        [   28,   240,     9,   119,    11,     8,  1508,  2157,  4068,     0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f89336a-c57f-4de7-9d84-20c7e4c5e92e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-52dbb17d0da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m         )\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either decoder_input_ids or decoder_inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;31m# past_key_values_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "model.model(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c54b496-3372-43cb-84ed-42efaf89acb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13959,  1566,    12,  2968,    10,    37,   629,    19,  1627,     5,\n",
       "             1]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68863ee1-bbc1-4ed6-8cb9-cc04cd63490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 512])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_decoder()(input_ids)['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d3558-94a1-48bb-9774-1fdb25507bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2c1ba1d-5db8-46db-b12c-44e626596772",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"The house is wonderful.\", \"I like to work in u.6v\"]\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output_sequences = model.generate(input_ids=inputs[\"input_ids\"],\n",
    "                                  attention_mask=inputs[\"attention_mask\"],\n",
    "                                  do_sample=False,\n",
    "                                  output_attentions=True,\n",
    "                                  output_hidden_states=True,\n",
    "                                  output_scores=True,\n",
    "                                  return_dict_in_generate=True)\n",
    "                                  # disable sampling to test if batching affects output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b28981b3-570d-4683-ad40-b2612a52b5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'sequences_scores', 'scores', 'beam_indices', 'encoder_attentions', 'encoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'decoder_hidden_states'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "97ebdac9-21e4-4b5a-9bd9-fba4b0333299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.8833, -11.5677, -10.2921,  ..., -13.6133, -13.6209,     -inf],\n",
       "        [ -9.8833, -11.5677, -10.2921,  ..., -13.6133, -13.6209,     -inf],\n",
       "        [ -9.8833, -11.5677, -10.2921,  ..., -13.6133, -13.6209,     -inf],\n",
       "        ...,\n",
       "        [ -8.3813, -11.7055, -12.6086,  ..., -13.9708, -13.9674,     -inf],\n",
       "        [ -8.3813, -11.7055, -12.6086,  ..., -13.9708, -13.9674,     -inf],\n",
       "        [ -8.3813, -11.7055, -12.6086,  ..., -13.9708, -13.9674,     -inf]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0402216d-97ed-4de8-9799-4515736548ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.3673, -10.1171,  -9.7802,  ..., -14.1245, -14.1317,     -inf],\n",
       "        [ -9.6910,  -7.1989,  -8.5523,  ..., -13.3171, -13.3654,     -inf],\n",
       "        [ -9.1201,  -9.9758,  -9.3361,  ..., -13.8836, -13.9023,     -inf],\n",
       "        ...,\n",
       "        [ -6.2548,  -8.0736,  -7.1292,  ..., -12.8266, -12.8382,     -inf],\n",
       "        [ -8.3927,  -8.9225,  -7.3705,  ..., -13.3349, -13.3512,     -inf],\n",
       "        [ -7.7695,  -5.3762,  -6.2260,  ..., -12.9911, -13.0367,     -inf]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences['scores'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cec603a5-08b6-4f0e-9e39-cbaeb7d20c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(0),\n",
       "  tensor(1),\n",
       "  tensor(1),\n",
       "  tensor(2),\n",
       "  tensor(1),\n",
       "  tensor(1),\n",
       "  tensor(1),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(3),\n",
       "  tensor(1)),\n",
       " (tensor(0),\n",
       "  tensor(1),\n",
       "  tensor(1),\n",
       "  tensor(2),\n",
       "  tensor(1),\n",
       "  tensor(1),\n",
       "  tensor(1),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(0),\n",
       "  tensor(2),\n",
       "  tensor(1),\n",
       "  tensor(0),\n",
       "  tensor(0)))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences['beam_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18814ed8-63ef-4989-9104-7335ed80e5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "300b34bb-593c-4e81-9c01-a72775f091ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65000,   789, 10095,    72, 37908,    12,    10,     0, 65000, 65000],\n",
       "        [65000, 13565,    38,   179,     6,     8,   135,  4068,   198,     0]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences['sequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a0611-6a4a-44a2-a078-0af31e7ff3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e577712-e8ed-4f4a-8b79-1847e00cf6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   26,  2793,    32, 15099,     6,     0, 65000, 65000, 65000, 65000],\n",
       "        [   28,   240,     9,   119,    11,     8,  1508,  2157,  4068,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa20ce9-5a55-4634-a837-5b78335502e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8886a2-4be0-4116-9c56-a70d34376c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we apply auto function as model\n",
    "the model has two ways.\n",
    "first, it is for training, second, it is for inference, evaluation, experiment.\n",
    "odict_keys(['loss', \n",
    "            'logits', \n",
    "            'decoder_hidden_states', \n",
    "            'decoder_attentions', \n",
    "            'cross_attentions', \n",
    "            'encoder_last_hidden_state', \n",
    "            'encoder_hidden_states', \n",
    "            'encoder_attentions'])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fb5b68-9db0-4469-84e5-24bee759351e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5164f-b84b-4146-8fbb-02dc5adddcae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
